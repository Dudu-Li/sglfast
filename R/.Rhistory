library(sglfast)
# We create beta="the true coefficient vector" to be used in the simulations.
beta = 1:5
# We generate the model matrix X with iid columns and rows and the response y
X = matrix(rnorm(100*400), nrow = 100)
y = X[,1:5]%*%beta
y = (1+exp(y))^-1
y
y = ((1+exp(y))^-1 > 0.5) + 0
y
# We generate the model matrix X with iid columns and rows and the response y
X = matrix(rnorm(100*400), nrow = 100)
y = X[,1:5]%*%beta
y = ((1+exp(y))^-1 > 0.5) + 0
y
mean(y)
# Rows in the training sample
train.idx = sample(100, 50)
# Group indices for the SGL
group_index = rep(1:40, each=10)
# Input data for the iterative
data.train = list(x=X[train.idx,], y=y[train.idx])
data.validate = list(x=X[-train.idx,], y=y[-train.idx])
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "logit")
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl_simple(data.train, data.validate, group_index, type = "logit")
# Best model returned by the iSGL algorithm
isgl.fit$beta
isgl.fit$intercept
# Best model returned by the iSGL algorithm
isgl.fit$beta
y
X[,1:5]%*%beta
y = X[,1:5]%*%beta
y = ((1+exp(-y))^-1 > 0.5) + 0
# Rows in the training sample
train.idx = sample(100, 50)
# Group indices for the SGL
group_index = rep(1:40, each=10)
# Input data for the iterative
data.train = list(x=X[train.idx,], y=y[train.idx])
data.validate = list(x=X[-train.idx,], y=y[-train.idx])
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl_simple(data.train, data.validate, group_index, type = "logit")
pmax(1:5,2:6)
a = 1:5
a[a==6]=0
a[a==6]=0
combn(1:5,2)
t(combn(1:5,2))
library(sglfast)
# We create beta="the true coefficient vector" to be used in the simulations.
beta = 1:5
# We generate the model matrix X with iid columns and rows and the response y
X = matrix(rnorm(100*400), nrow = 100)
y = X[,1:5]%*%beta
# We chose the variance of the error such that SNR = 3
snr = 3
error = rnorm(100, mean = 0, sd=sqrt(var(y)/snr))
y = y+error
# Rows in the training sample
train.idx = sample(100, 50)
# Group indices for the SGL
group_index = rep(1:40, each=10)
# Input data for the iterative
data.train = list(x=X[train.idx,], y=y[train.idx])
data.validate = list(x=X[-train.idx,], y=y[-train.idx])
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl_simple(data.train, data.validate, group_index, type = "linear")
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "linear")
isgl.fit$beta
# Best model returned by the iSGL algorithm
sum(isgl.fit$beta!=0)
debug(sglfast::isgl_simple)
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl_simple(data.train, data.validate, group_index, type = "linear")
undebug(sglfast::isgl_simple)
library(sglfast)
# We create beta="the true coefficient vector" to be used in the simulations.
beta = 1:5
# We generate the model matrix X with iid columns and rows and the response y
X = matrix(rnorm(100*400), nrow = 100)
y = X[,1:5]%*%beta
# We chose the variance of the error such that SNR = 3
snr = 3
error = rnorm(100, mean = 0, sd=sqrt(var(y)/snr))
y = y+error
# Rows in the training sample
train.idx = sample(100, 50)
# Group indices for the SGL
group_index = rep(1:40, each=10)
# Input data for the iterative
data.train = list(x=X[train.idx,], y=y[train.idx])
data.validate = list(x=X[-train.idx,], y=y[-train.idx])
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl_simple(data.train, data.validate, group_index, type = "linear")
isgl.fit$beta
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "linear")
# Best model returned by the iSGL algorithm
sum(isgl.fit$beta!=0)
isgl.fit$beta!=0
isgl.fit$beta
# We create beta="the true coefficient vector" to be used in the simulations.
beta = 1:5
# We generate the model matrix X with iid columns and rows and the response y
X = matrix(rnorm(100*400), nrow = 100)
y = X[,1:5]%*%beta
# We chose the variance of the error such that SNR = 3
snr = 3
error = rnorm(100, mean = 0, sd=sqrt(var(y)/snr))
y = y+error
# Rows in the training sample
train.idx = sample(100, 50)
# Group indices for the SGL
group_index = rep(1:40, each=10)
# Input data for the iterative
data.train = list(x=X[train.idx,], y=y[train.idx])
data.validate = list(x=X[-train.idx,], y=y[-train.idx])
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "linear")
# Best model returned by the iSGL algorithm
sum(isgl.fit$beta!=0)
isgl.fit$beta
isgl.fit$intercept
isgl.fit$best_lambdas
# We create beta="the true coefficient vector" to be used in the simulations.
beta = 1:5
# We generate the model matrix X with iid columns and rows and the response y
X = matrix(rnorm(100*400), nrow = 100)
y = X[,1:5]%*%beta
y = ((1+exp(-y))^-1 > 0.5) + 0
# Rows in the training sample
train.idx = sample(100, 50)
# Group indices for the SGL
group_index = rep(1:40, each=10)
# Input data for the iterative
data.train = list(x=X[train.idx,], y=y[train.idx])
data.validate = list(x=X[-train.idx,], y=y[-train.idx])
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl_simple(data.train, data.validate, group_index, type = "logit")
# Best model returned by the iSGL algorithm
isgl.fit$beta
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "logit")
# Best model returned by the iSGL algorithm
isgl.fit$beta
isgl.fit$intercept
group_index
library(sglfast)
# We create beta="the true coefficient vector" to be used in the simulations.
beta = 1:5
# We generate the model matrix X with iid columns and rows and the response y
X = matrix(rnorm(100*400), nrow = 100)
y = X[,1:5]%*%beta
# We chose the variance of the error such that SNR = 3
snr = 3
error = rnorm(100, mean = 0, sd=sqrt(var(y)/snr))
y = y+error
# Rows in the training sample
train.idx = sample(100, 50)
# Group indices for the SGL
group_index = rep(1:40, each=10)
# Input data for the iterative
data.train = list(x=X[train.idx,], y=y[train.idx])
data.validate = list(x=X[-train.idx,], y=y[-train.idx])
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "linear")
# Best model returned by the iSGL algorithm
sum(isgl.fit$beta!=0)
isgl.fit$beta
isgl.fit$best_lambdas
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "linear")
library(sglfast)
# We create beta="the true coefficient vector" to be used in the simulations.
beta = 1:5
# We generate the model matrix X with iid columns and rows and the response y
X = matrix(rnorm(100*400), nrow = 100)
y = X[,1:5]%*%beta
# We chose the variance of the error such that SNR = 3
snr = 3
error = rnorm(100, mean = 0, sd=sqrt(var(y)/snr))
y = y+error
# Rows in the training sample
train.idx = sample(100, 50)
# Group indices for the SGL
group_index = rep(1:40, each=10)
# Input data for the iterative
data.train = list(x=X[train.idx,], y=y[train.idx])
data.validate = list(x=X[-train.idx,], y=y[-train.idx])
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "linear")
# Best model returned by the iSGL algorithm
sum(isgl.fit$beta!=0)
isgl.fit$beta
isgl.fit$best_lambdas
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "linear")
library(sglfast)
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "linear")
# Best model returned by the iSGL algorithm
sum(isgl.fit$beta!=0)
isgl.fit$beta
isgl.fit$intercept
isgl.fit$best_lambdas
library(sglfast)
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl_simple(data.train, data.validate, group_index, type = "linear")
isgl.fit$beta
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "linear")
isgl.fit$beta
library(sglfast)
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl_simple(data.train, data.validate, group_index, type = "linear")
isgl.fit$beta
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "linear")
isgl.fit$beta
isgl.fit$best_lambdas
# We create beta="the true coefficient vector" to be used in the simulations.
beta = 1:5
# We generate the model matrix X with iid columns and rows and the response y
X = matrix(rnorm(100*400), nrow = 100)
y = X[,1:5]%*%beta
# We chose the variance of the error such that SNR = 3
snr = 3
error = rnorm(100, mean = 0, sd=sqrt(var(y)/snr))
y = y+error
# Rows in the training sample
train.idx = sample(100, 50)
# Group indices for the SGL
group_index = rep(1:40, each=10)
# Input data for the iterative
data.train = list(x=X[train.idx,], y=y[train.idx])
data.validate = list(x=X[-train.idx,], y=y[-train.idx])
# We run the (unpooled) iterative SGL. For the 2-parameter version use isg_simple()
isgl.fit = isgl(data.train, data.validate, group_index, type = "linear")
isgl.fit$beta
isgl.fit$best_lambdas
